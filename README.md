# ðŸ¤– Chatbot Flask (avec TinyLLaMA local)

Ce projet est un chatbot dÃ©veloppÃ© avec **Flask** et conÃ§u pour intÃ©grer un modÃ¨le IA de type LLaMA en local. Il met l'accent sur la **rÃ©duction des dÃ©pendances lourdes**, la **personnalisation linguistique** (BaoulÃ©, Dioula), et une **architecture propre** adaptÃ©e aux environnements limitÃ©s.

---

## ðŸ“ Structure du dÃ©pÃ´t

â”œâ”€â”€ ai/ # Logique de traitement du chatbot â”œâ”€â”€ app.py  # Point dâ€™entrÃ©e de lâ€™application Flask â”œâ”€â”€ model_config.py # ParamÃ¨tres du modÃ¨le IA local â”œâ”€â”€ setup.sh  # Script dâ€™installation pour lâ€™environnement local â”œâ”€â”€ templates/ # Pages HTML (interface utilisateur) â”œâ”€â”€ static/ # Fichiers CSS, JS, images â”œâ”€â”€ requirements.txt  # DÃ©pendances Python â”œâ”€â”€ .gitignore # Fichiers exclus du dÃ©pÃ´t

---

## âš ï¸ ModÃ¨les LLaMA non inclus

Les dossiers `llama2_model/`, `llama_env/` et `test_llama_local.py` **ne sont pas poussÃ©s sur GitHub** pour Ã©viter dâ€™alourdir le dÃ©pÃ´t.

> ðŸ’¡ Pour utiliser le chatbot avec le modÃ¨le LLaMA, place les fichiers requis localement dans ton environnement selon cette structure :

llama2_model/ â”‚ â””â”€â”€ model.bin  llama_env/ â”‚ â””â”€â”€ tokenizer.model

---

## ðŸ”§ Installation locale

1. Clone le repo :
```bash
git clone https://github.com/Charlem777/Chatbot_flask.git
cd Chatbot_flask
CrÃ©e un environnement virtuel :
bash
python -m venv .venv
source .venv/bin/activate
Installe les dÃ©pendances :
bash
pip install -r requirements.txt
Lance le chatbot :
bash
python app.py
